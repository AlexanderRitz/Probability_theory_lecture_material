\documentclass{beamer}

\mode<presentation> {

\usetheme{Madrid}

}
\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage{amsmath}
\usepackage[utf8]{inputenc} 
\usepackage[T1]{fontenc} 
\usepackage{lmodern} 
\usepackage{ngerman}
\usepackage{amsmath}
\usepackage{eurosym}
\usepackage{glossaries-extra}

\setbeamersize{text margin left=8mm}
\setbeamersize{text margin right=8mm}

\usepackage{mathtools} 
\usepackage{mathrsfs} 

\usepackage{xcolor}

\newcommand*\diff{\mathop{}\!\mathrm{d}}
\newcommand*\Diff[1]{\mathop{}\!\mathrm{d^#1}}
\newcommand{\E}{\mbox{I\negthinspace E}}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title[Advanced Statistical Inference]{A Gentle Introduction to Probability Theory} % The short title appears at the bottom of every slide, the full title is only on the title page

\author{Alexander Ritz} % Your name
\institute[University of Göttingen] % Your institution as it will appear on the bottom of every slide, may be shorthand to save space
{
University of Göttingen \\ % Your institution for the title page
\medskip

}
\date{\today} % Date, can be changed to a custom date

\begin{document}

\begin{frame}
\titlepage % Print the title page as the first slide
\end{frame}

\begin{frame}
\frametitle{Overview} % Table of contents slide, comment this block out to remove it
\tableofcontents % Throughout your presentation, if you choose to use \section{} and \subsection{} commands, these will automatically be printed on this slide as an overview of your presentation
\end{frame}



%------------------------------------------------
\section{Probability Spaces} 
%------------------------------------------------
\frame{\sectionpage}

\begin{frame}
\frametitle{Sample Space}

Let $\Omega$ denote the set of all potential outcomes or results $\omega$ of a random experiment.\\
Then $\Omega$ is called sample space or possibility space. 

\end{frame}


\begin{frame}
\frametitle{Events}

Any subset  $ A \subset \Omega $ is called an event.

\end{frame}


\begin{frame}
\frametitle{$\sigma$ -Algebra}

A system $\mathscr{A}$ of subsets of $\Omega$ is called $\sigma$-Algebra in $\Omega$, if it has the following properties:
\newline
\begin{itemize}
\pause
\item{$\Omega \in \mathscr{A}$}
\pause
\item{$A \in \mathscr{A} \implies A^{\mathrm{C}} \in \mathscr{A}$}
\pause
\item{$A_1, A_2, A_3, ... \in \mathscr{A} \implies \bigcup\limits_{l \in \mathbb{N}} A_l \in \mathscr{A}$}
\end{itemize}

\end{frame}


\begin{frame}
\frametitle{Power Set}

The power set of a set $A$ is given by 
\[
\mathcal{P}(A) := \{M \mid M \subset A\},
\]
being the set of all subsets $M$ of $A$.
It holds that $\mid \mathcal{P}(A)\mid = 2^{ \mid A\mid}$.

\end{frame}


\begin{frame}
\frametitle{Generated $\sigma$-Algebra}

Given an arbitrary family of subsets $F$ of a sample space $\Omega$, the $\sigma$-algebra
\[
\sigma (F) := \bigcap_{F \subset \mathscr{A}} \mathscr{A} , \quad \text{with }\mathscr{A}\text{ being }\sigma \text{-algebras on } \Omega
\]
denotes the smallest $\sigma$-algebra on $\Omega$, which contains $F$.

\end{frame}


\begin{frame}
\frametitle{Borel $\sigma$-Algebra}

Given $\Omega = \mathbb{R}$ and $I:= \{ (s, t): -\infty  \leq s \leq t \leq \infty \}$, the $\sigma$-algebra generated by the open intervals $I$ are usually denoted
\[
\mathscr{B} (\mathbb{R}) := \sigma (I)
\]
This is called the Borel $\sigma$ algebra on $\mathbb{R}$. By definition of $\sigma$-algebras, $\mathscr{B}$ contains all open, closed and half open intervals.

\end{frame}


\begin{frame}
\frametitle{Measurable Space}

A tuple $(\Omega, \mathscr{A})$, consisting of a sample space $\Omega$
 and a $\sigma$-algebra $A \subset \mathcal{P}(\Omega)$ is called measurable space.

\end{frame}


\begin{frame}
\frametitle{Measures}

Let $\mathscr{A}$ be a $\sigma$-algebra. A function $\mu : \mathscr{A} \to [0, \infty]$ is called a measure
on $\mathscr{A}$, if
\begin{itemize}
\pause
\item{$\mu(\emptyset) = 0$}
\pause
\item{$\mu$ is $\sigma$-additive, i.e. for all sequences of pairwise disjoint sets $A_1, A_2, . . .$ holds: \[
\mu\left( \dot{\bigcup\limits_{i \in \mathbb{N}}}A_i \right) = \sum_{i \in \mathbb{N}}\mu(A_i)
\]}
\end{itemize}

\end{frame}


\begin{frame}
\frametitle{Probability Measures}

Let $\mathscr{A}$ be a $\sigma$-algebra on the sample space $\Omega$. A function $P : \mathscr{A} \to [0, 1]$ is called probability measure
on $\mathscr{A}$, if
\begin{itemize}
\pause
\item{$P(\Omega) = 1$}
\pause
\item{$P$ is $\sigma$-additive, that is, for all sequences of pairwise disjoint sets $A_1, A_2, . . .$ holds: \[
P\left( \dot{\bigcup\limits_{i \in \mathbb{N}}}A_i \right) = \sum_{i \in \mathbb{N}}P(A_i)
\]}
\end{itemize}

\end{frame}


\begin{frame}
\frametitle{Probability Space}

The triple $(\Omega, \mathscr{A}, P)$, consisting of a sample space $\Omega$, a $\sigma$-algebra $\mathscr{A}$ on $\Omega$ and a probability measure $P$ defined on $\mathscr{A}$, is called probability space.

\end{frame}


\section{Random Variables} 


\begin{frame}
\frametitle{Random Quantities}

A function on the sample space $\Omega$ \[
X : \Omega \to \mathbb{R}^d \quad \text{  with  }\quad \omega \mapsto X(\omega)
\]
is called random quantity. \newline
\pause
In case of $d=1$, $X$ is called a random variable. \newline
\pause
In case of $d>1$ $X$ is a vector of random variables, that is $X = (X_1, . . . , X_d)$. In that case, $X$ is called $d$-dimensional random vector. \newline
\pause
The function does \textcolor{red}{not} have to be real valued, but the concept generalises trivially!

\end{frame}


\begin{frame}
\frametitle{Measurability}

In order to facilitate the notation of the following concepts, we define:
\[
X^{-1}(\left] -\infty, z \right] ) = \{ \omega \in \Omega \mid -\infty < X(\omega) \leq z \} =: \{ X \leq z \}
\]

\end{frame}


\begin{frame}
\frametitle{Measurability}

A random quantity $X : \Omega \to \mathbb{R}^d $ is called measurable with respect to the $\sigma$-algebra $\mathscr{A}$, if:
\[
\forall z \in \mathbb{R}^d : \{X \leq z\} \in \mathscr{A}
\]
with $\{X \leq z\} \in \mathscr{A}$ being shorthand for the set of outcomes $\omega \in \Omega$, for which the function $X = (X_1, . . . , X_d)$ results in values below $z = (z_1, . . . , z_d)$, i.e.:
\[
\{X \leq z\} = \{\omega \in \Omega \mid X(\omega) \leq z\} = \{\omega \in \Omega \mid X_1(\omega)\leq z_1, ..., X_d(\omega)\leq z_d\}
\]

\end{frame}



\section{Distributions} 


\begin{frame}
\frametitle{Distributions of Random Variables}

Let $X: \Omega \to \mathbb{R}^d$ be a measurable random variable on the measure space $(\Omega, \mathscr{A})$. The probabilities of \textit{all} events belonging to $X$ as a whole are called \textit{probability distribution} or \textit{cumulative distribution} of the random variable $X$. The entire distribution is determined by the function:
\begin{align}
F_X: \mathbb{R}^d &\to \left[ 0, 1\right] \\
z &\mapsto F_X(z):= P(\{X \leq z\}) = P(\{X_1 \leq z_1, \dots , X_d \leq z_d\}),
\end{align}
leading to $F_X$ being called \textit{distribution function} of $X$

\end{frame}


\begin{frame}
\frametitle{Distribution Function}

Using \textit{Riemann-Stieltjes integrals}, one can write:
\[
P(\{ a < X \leq b\}) = F_X(b) - F_X(a) = \int_a^b \diff F_X(z)
\]
, given that $F_X$ is continuous. 

\end{frame}


\begin{frame}
\frametitle{Distribution Function}

In case $F_X$ is differentiable, the probabilities can be given as:
\[
\int_a^b \diff F_X(z) = \int_a^b F^{\prime}_X(z)\diff z
\]
Under the further restriction that $F_X^{\prime}$ be continuous, the following holds for infinitesimal changes $\diff z$:
\[
P(\{ z < X \leq z + \diff z\} ) = F_X(z + \diff z) - F_X(z) = F^{\prime}_X(z)\diff z = \diff F_X(z)
\]

\end{frame}


\begin{frame}
\frametitle{Density Function}

If a function $f:\mathbb{R} \to \mathbb{R}$ exists with
\[
F_X(z) = \int_{- \infty}^{z} f(s) ds
\]
, it is called density function of $X$. In case $f$ is continuous, $F_X^\prime = f$ follows.

\end{frame}


\section{Moments} 


\begin{frame}
\frametitle{Expected Value}

 The expected value $\E (X)$ of a random variable $X$ is defined as its mean function value
\[
\E (X) = \int_{\mathbb{R}^d } z \diff F_X(z)
\]

\end{frame}


\begin{frame}
\frametitle{Variance and Standard Deviation}
The variance $\Var (X)$ of a random variable $X$ is defined as the quadratic deviation of $X$ from its expected value, i.e.
\[
\Var (X) = \E (\mid X - \E (X) \mid ^2)
\]
A better intuition of the strength of dispersion can be had by examining the \textit{standard deviation} $s(X)$
\[
s(X) := \sqrt{\Var (X)}
\]

\end{frame}


\section{Convergence of Random Variables} 


\begin{frame}
\frametitle{Deterministic Convergence}

Recall that convergence towards a limit $L$ for a deterministic sequence $S_n$, with $n \in \mathbb{N}$, can be expressed by
\[
\forall \epsilon > 0 \quad \exists N: \quad \forall n \geq N : \quad|S_n - L| < \epsilon
\]

\end{frame}


\begin{frame}
\frametitle{Convergence in Probability}

A sequence of random variables $X_1, X_2, ...$, denoted by $X_n$, is said to converge in probability towards $X$, written as $X_n \overset{P}\to X$ or $\text{plim}_{n \to \infty} X_n  = X$, if
\[
\forall \epsilon > 0 :\quad P(|X_n - X| > \epsilon) \to 0 \quad \text{as} \quad n \to \infty
\]

\end{frame}


\begin{frame}
\frametitle{Convergence in Distribution}

$X_n$ is said to \textit{converge in distribution} towards $X$, written as $X_n \overset{D}\to X$, if 
\[
\forall x \in \mathbb{R} : \quad P(X_n \leq x) \to P(X \leq x) \quad \text{as} \quad n \to \infty
\]
, given that $P(X \leq x)$ is continuous at $x$.

\end{frame}


\begin{frame}
\frametitle{Convergence in rth Mean}

$X_n$ converges \textit{in rth mean} (for $r \geq 1$), written as $X_n \overset{r}\to X$, if 
\[
\forall n \in \mathbb{N}: \quad \E{(|X_n|^r)} < \infty 
\] and 
\[
\E{(|X_n - X|^r)} \to 0 \quad \text{as} \quad n \to \infty
\]

\end{frame}

%------------------------------------------------



%------------------------------------------------




\end{document}